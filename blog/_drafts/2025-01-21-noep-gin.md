---
title: "NÃ¶pp Gin Web Application" 
---

IMAGE HERE

I recently had the pleasure to complete an interesting project involving WebGL and live green screen keying.

IMAGE HERE

As always with such things, the concept seemed simple at first glance. The idea was that the gin bottle would have a flat green label printed on it to act as a greenscreen and when viewed through a phone camera it would be keyed out to reveal a video playing "on" the label.

## Prototype

I started creating a rough proof of concept prototype uing plain Javascript and WebGL to see how well I could key out a greenscreen cylinder viewed through a webcam.

Usually the lighting conditions are granually controlled in a studio setting to make sure that the light on the greenscreen is as uniform as possible to make sure that the green colors are easy to isolate in post production.

I did not have that luxury. Anybody would be able to use their phone to look at the green label of the bottle in any light condition.

## Simple Hue Keying

One way to isolate a certain color in an image is to convert the color RGB information into HSV( Hue, Saturation, Value ). This way the hue information is independent from saturation and brightness.

IMAGE HERE

Green areas in image can then be selected by a range in the hue, saturation and value space.

I implemented a feature which allowed the user to select the green label on their screen so that i could get the correct ranges in any light condition.

Although this worked well enough I was not satisfied with this solution. It seemed too "fiddly" to have to select the green color on your phone. But we needed to move on to building the final application.

## Application

In addition to the realtime color keying, the client also requested that the videos shown could be customized. So they could have unique QR codes on some of the bottles for more personalized video message on the label.

This was solved by utilizing url parameters which would choose the needed video file from a directory on the server.

I decided to use Vite framework with Typescript to make application development as fast and reliable as possible.

Using a WebGL library like ThreeJS did cross my mind, but I decided to use WebGL directly instead to get more control over the rendering state.

The management of shader code files was very convenient with Vite as it allows to import files as strings into Typescript and Javascript. These would later be embedded into the built single javascript file.

## Better Color Keying

As mentioned before, I was not satisfied with the current manual color range selection method. So I experimented with other ways to select green hues.

When looking at different colorspace coordinate systems I noticed that the LAB colorspace similarly has the hue component separated from others but the data is more intuitively formatted with the opposing hues being the extremes of 2 axes.

IMAGE HERE

HLS hue values are encoded as degrees on single dimension to represent different hues.

IMAGE HERE

LAB has 2 hue related axes (A, B). More information about the hue is encoded this way and it gives better spatial separation between the different hue values.

IMAGE HERE

Hues can be more precisely be selected by a "3D position" in the LAB space. So instead of HSV minimum and maximum range the color could be slected by how far it is in the LAB 3D coordinate space from any target point.

I did not expect much improvement when I set out to experiment with using the LAB space but to my surprise it worked shockingly well. 

The green target color in the space could now be hardcoded, which meant I could finally do away with requiring the user to select the color on their screen.

## WebGL Details

The graphics logic was all in 2D which made building the rendering pipeline easier. Using raw WebGL enabled me to tightly control every aspect of the rendering process.

### Framebuffers

I split different stages into multiple framebuffers which I could then composite in a final fragment shader for the complete look.

Framebuffers:
 - 0
    - Video File RGB

 - 1 (2 color attachments)
    - Camera Video RGB (for displaying)
    - Camera Video LAB (for keying)

 - 2
    - Greenscreen mask R

 - 3 (Main Framebuffer)
    - Composited Effect RGB

### Shaders

There was no need to do anything special in the vertex shaders as I only needed to draw fullscreen quads. The vertex position attribute was optimized to have only 2D vectors.

RGB to LAB colorspace conversion was the most complicated part of the shader code in this project.

```glsl
vec4 rgb_to_lab(vec4 rgb){
    vec4 res = vec4(0.0);
    // Convert RGB to XYZ
    vec3 xyz = vec3(
        0.412453 * rgb.r + 0.357580 * rgb.g + 0.180423 * rgb.b,
        0.212671 * rgb.r + 0.715160 * rgb.g + 0.072169 * rgb.b,
        0.019334 * rgb.r + 0.119193 * rgb.g + 0.950227 * rgb.b
    );

    // Convert XYZ to LAB
    float l = 116.0 * lab_f(xyz.y) - 16.0;
    float a = 500.0 * (lab_f(xyz.x) - lab_f(xyz.y));
    float b = 200.0 * (lab_f(xyz.y) - lab_f(xyz.z));

    // Scale LAB values to [0, 1] range
    l = (l + 16.0) / 132.0; // L: [0, 100] -> [0, 1]
    a = (a + 128.0) / 256.0; // a: [-128, 127] -> [0, 1]
    b = (b + 128.0) / 256.0; // b: [-128, 127] -> [0, 1]
    res.xyz = vec3(l,a,b);
    return res;
}
```

As you can see, the conversion is far from trivial and I am not going to pretend to understand every aspect of this. The main thing is that it works well enough to convert RGB data into LAB color data.

### Edge Effect

IMAGE HERE

